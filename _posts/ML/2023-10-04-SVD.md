---
layout: single
title: "Singular Value Decomposition (SVD)"
categories: ML
tag: [ML]
author_profile: false
search: true
use_tex: true
---

> 특이값 분해(Singular Value Decomposition, SVD)는 임의의 행렬을 세 개의 행렬의 곱으로 분해하는 선형대수학 기법으로, 원본 행렬의 정보를 보존하면서 차원을 축소하거나, 노이즈를 제거하며, 또한 머신러닝과 데이터 분석에서 주로 사용

- Dimension reduction 보다는, <span style='color:orange'>data compression</span> 하는 방법
- Eigen decompostion (고유값 분해) 처럼, diagonalisation of matrix(행렬의 대각화) 하는 방법으로, **모든 크기의 $m \times n$ matrix A 에 대해 적용 가능**하다.
- <span style='color:orange'>${A=U\sum V^T}$</span>
- $U$ 와 $V$ 는 각각 $m \times m, n \times n$ 크기의 orthogonal matrix 이며, $\sum$ 는 $m \times n$ 행렬이다.
- Orthogonal Matrix (직교 행렬) 이란, Transposed matrix (전치 행렬) 이 Inverse matrix (역행렬) 가 되는 matrix

<img width="650" alt="PM" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/fde39a6a-e9ae-40fc-b42f-cffeca58c7b0">{: .align-center}

- SVD’s geometric meaning (기하학적 의미) 는 아래와 같다.
  - 2x2 size 의 orthogonal matrix 는 다음의 shape 와 equivalent 하다.

<img width="650" alt="PM" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/b77dc662-d3e6-46b6-94fc-253142855579">{: .align-center}

  - $\epsilon=1$ 일 때에는 <span style='color:orange'>Rotation matrix (회전 변환 행렬)</span> 과 같은 shape 이며, $\epsilon = -1$ 일 때에는 inverse 된 Reflection rotation matrix 를 의미한다.
  - <span style='color:orange'>Diagonal matrix (대각 행렬) 는 each axle 로의 scale transformation</span> 을 의미한다.
- Matrix A 의 linear transformation 을 rotation transformation 과 scale transformation 으로 divide 하는 것이 SVD 이다.
- SVD, <span style='color:orange'>${(A=U\sum V^T)}$</span>

<img width="635" alt="img" src="https://github.com/woo-kyu/woo-kyu.github.io/assets/102133610/5c55f5c7-38c5-49dd-96ae-ac11ba3f35c4">{: .align-center}


- U 는 <span style='color:orange'>${AA^T}$</span> 의 eigenvector 를 column vector 로 가지고 있는 matrix 로, 이 때의 ‘column vectors 를 left singular vector of A’ 라고 부른다.
  - $U=[u_1 \ u_2 \ ... u_m], \ (AA^T)u_i=\lambda_iu_i$
- V 는 <span style='color:orange'>${A^TA}$</span> 의 eigenvector 를 column vector 로 가지고 있는 matrix 로, 이 때의 ‘column vectors 를 right singular vector of A’ 라고 부른다.
  - $V=[v_1 \ v_2 \ ... v_n], \ (A^TA)v_i=\lambda_iv_i$
- $\sum$ 는 <span style='color:orange'>${AA^T}$</span> 또는 <span style='color:orange'>${A^TA}$</span> 의 eigenvalue 들의 root value ($\sigma$) 를 diagonal element 로 하는 $m \times n$ rectangle diagonal matrix 이다.(직 사각 대각 행렬)
- 이 때의 elements 가 <span style='color:#ff00ff'>Singular value (특이값)</span> 이다.

$$
\sum = \begin{bmatrix}
\sigma_1 & &  \\
& \ddots  &  \\
&  & \sigma_n \\
&  & 0 \\
\end{bmatrix} (m>n)\\ \textrm{ or }  \sum = \begin{bmatrix}
\sigma_1 &  &  &  \\
& \ddots  &  &  \\
&  & \sigma_m & 0 \\
\end{bmatrix} (m< n)
$$

# Property in SVD

- $\orange{AA^T}$ 와 $\orange{A^TA}$ 는 모두 square matrix 이므로 eigen decompostion 가능하다.
- 이 때의 eigenvalue 는 모두 over the 0
- $A^TAv=\lambda v \Rightarrow v^TA^TAv = \lambda v^Tv \Rightarrow(Av)^TAv=\lambda v^Tv \\ \Rightarrow \orange{||Av||^2=\lambda||v||^2}$
- 0 이 아닌 eigenvalue 는 서로 같으며, 하나의 matrix $\sum$ 으로 표현.

$A^TAv =\lambda v \Rightarrow A(A^TA)v=\lambda Av \Rightarrow AA^T(Av)=\lambda(Av). \\ \textrm{if} \  Av\neq0$ ($Av=0$ 이면, $Av=\lambda v$ 이므로 eigenvalue 는 0이 되기 때문에, unassumption.)

- For reference, there is existable when eigenvalue is 0
- $Au=\lambda u=0$
- Due to eigenvector cant be exiest 0-vector, A is only singular matrix without inverse matrix.

- $\sum = \begin{bmatrix}
  \sigma_1 & &  \\
  & \ddots  &  \\
  &  & \sigma_n \\
  &  & 0 \\
  \end{bmatrix} (m>n)$ 에서,
  - m > n 일 때에는 $u_{n+1},...,u_m$ eigenvector’s eigenvalue is 0.
    - $AA^T$  matrix 가 singular matrix 이다.
  - $\sigma_1,...,\sigma_n \ge 0$ 이므로, 0 값인 singular value 가 possible to exist
    - $A^TA$  matrix 가 singular matrix 이다.
  - $\sigma_n=0$ 이라면, $u_n,u_{n+1},...,u_m$ eigenvector 의 sequence는 random으로 바뀌어도 irrelevant 하다.

# Data Compression using SVD

## Case ; Decompose an $m\times n$ matrix using SVD

- Full SVD

  ![Screenshot 2023-03-14 at 11.52.42 PM.png](Singular%20Value%20Decompostion%20(SVD)%205da6cb1712364bd9845ae07a13698a02/Screenshot_2023-03-14_at_11.52.42_PM.png)

- Thin SVD (Output : 동일한 matrix A)

  ![Screenshot 2023-03-14 at 11.53.49 PM.png](Singular%20Value%20Decompostion%20(SVD)%205da6cb1712364bd9845ae07a13698a02/Screenshot_2023-03-14_at_11.53.49_PM.png)

- Compact SVD (Output : 동일한 matrix A. 0의 singular value 를 제외하는 method)

  ![Screenshot 2023-03-14 at 11.54.09 PM.png](Singular%20Value%20Decompostion%20(SVD)%205da6cb1712364bd9845ae07a13698a02/Screenshot_2023-03-14_at_11.54.09_PM.png)

- Truncated SVD (Output : Approximate matrix $A'$. 작은 singular value 까지 제외하는 method)

  ![Screenshot 2023-03-14 at 11.59.24 PM.png](Singular%20Value%20Decompostion%20(SVD)%205da6cb1712364bd9845ae07a13698a02/Screenshot_2023-03-14_at_11.59.24_PM.png)